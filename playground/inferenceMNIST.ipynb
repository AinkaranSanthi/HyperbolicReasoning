{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "import IPython.display\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.train import Trainer\n",
    "from src.utils import set_requires_grad\n",
    "from clsmodel import mnist, stl10, afhq\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load exp config\n",
    "model_path = './LOGS/MNIST/models/best.pth'\n",
    "\n",
    "#data-folder-path\n",
    "folder_path = '../datasets/MNIST'\n",
    "\n",
    "config = json.load(open(os.path.join(os.path.dirname(os.path.dirname(model_path)), 'exp-config.json'), 'r'))\n",
    "\n",
    "# config['classifier'] = afhq(32, True).cuda(0)\n",
    "config['classifier'] = mnist(32, 'it').cuda(0)\n",
    "\n",
    "model = Trainer(**config)\n",
    "model.load_model(model_path)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# model defns\n",
    "feature_extractor = model.feature_extractor\n",
    "conti_classifier = model.classifier_baseline\n",
    "dis_classifier = model.classifier_quantized\n",
    "decoder = model.dec\n",
    "codebook_sampler = model.modelclass\n",
    "\n",
    "\n",
    "# set_requires_grad(classifier, False)\n",
    "set_requires_grad(feature_extractor, False)\n",
    "set_requires_grad(conti_classifier, False)\n",
    "set_requires_grad(dis_classifier, False)\n",
    "set_requires_grad(decoder, False)\n",
    "set_requires_grad(codebook_sampler, False)\n",
    "    \n",
    "\n",
    "# required config variables \n",
    "image_size = model.input_size\n",
    "latent_dim = model.latent_size\n",
    "num_classes = model.nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import get\n",
    "\n",
    "batch_size = 16\n",
    "train_loader, test_loader = get(batch_size, \n",
    "                      data_root = folder_path, \n",
    "                      train=True, val=True, \n",
    "                      input_size = image_size,\n",
    "                      num_workers=10)\n",
    "\n",
    "\n",
    "orig_images = []; orig_labels = []\n",
    "for (img_batch, label_batch, *context_batch) in tqdm(test_loader):\n",
    "    img_batch = img_batch.cuda(0)\n",
    "    label_batch = label_batch.cuda(0)\n",
    "    orig_images.extend(img_batch)\n",
    "    orig_labels.extend(label_batch)\n",
    "\n",
    "\n",
    "labels_ = np.array([lb.cpu().numpy() for lb in orig_labels])\n",
    "# generate sample dataset\n",
    "def get_sample_data(N_datapoints = 10): \n",
    "    sample_images = []; sample_labels = []\n",
    "    for ci in range(num_classes):\n",
    "        idxs = np.where(labels_ == ci)[0]\n",
    "        randidxs = idxs[np.random.randint(0, len(idxs), N_datapoints//num_classes)]\n",
    "\n",
    "        for idx in randidxs:\n",
    "            sample_images.append(orig_images[idx].unsqueeze(0))\n",
    "            sample_labels.append(orig_labels[idx].unsqueeze(0))\n",
    "\n",
    "    sample_images = torch.cat(sample_images, dim = 0)\n",
    "    sample_labels = torch.cat(sample_labels, dim = 0)\n",
    "    return sample_images, sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import InductiveReasoningDT\n",
    "\n",
    "inferer = InductiveReasoningDT(get_sample_data(100),\n",
    "                               ncodebook_features = model.codebook_size,\n",
    "                               nclasses = num_classes,\n",
    "                               train_loader = train_loader,\n",
    "                               feature_extractor = feature_extractor,\n",
    "                               codebook = codebook_sampler,\n",
    "                               classifier = dis_classifier,\n",
    "                               decoder = decoder)\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_sampler.reasoningLayers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci in range(num_classes):\n",
    "    inferer.get_class_tree(ci,f'./MNISTLOGS/class-{ci}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci in range(num_classes):\n",
    "    \n",
    "    for i in range(10):\n",
    "        x,y = get_sample_data(num_classes)\n",
    "        x = x[ci].unsqueeze(0)\n",
    "\n",
    "        inferer.get_local_tree(ci, x, f'./MNISTLOGS/class-{ci}/img{i}')\n",
    "        inferer.query(ci, visual = x, local=True, overlay=True, save_path=f'./MNISTLOGS/class-{ci}/img{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
